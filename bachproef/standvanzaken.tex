\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}
\label{ch:stand-van-zaken}

\section{Virtualisatie}
\subsection{De geschiedenis van virtualisatie}

Abstract beschreven is virtualisatie een term die verwijst naar de abstractie van computerbronnen. Het doel van een virtuele computer omgeving is het gebruik van hulpbronnen/resources te verbeteren door middel van een geïntegreerd besturingsplatform voor gebruikers en applicaties gebaseerd op aggregatie van heterogene en autonome middelen. Tegenwoordig is virtualisatie op meerdere niveaus belangrijk om systeembeveiliging, betrouwbaarheid en beschikbaarheid te verbeteren en garanderen alsook het verminderen van kosten en zorgen voor meer flexibiliteit. Virtualisatie is snel uitgegroeid tot een go-to-technologie voor het verhogen van de efficiëntie. Virtualisatie biedt een enorme flexibiliteit, zo kunnen ongelijksoortige architecturen (Linux, MacOS, Windows,...) op één enkele machine tegelijkertijd worden ingezet zonder interferentie \autocite{Radhwan2013}.

Virtualisatie is een techniek waarin alle fysieke kenmerken van computerbronnen verborgen worden waarvan applicaties, andere systemen en toepassingen gebruik kunnen maken. Het is een softwareabstractielaag tussen de hardware en het besturingssysteem en de toepassingen die erbovenop draaien. Dit wordt een hypervisor of virtual machine monitor(VMM) genoemd. Doordat de hardwarebronnen door de VMM/hypervisor worden gebruikt en niet door de host, is het mogelijk meerdere besturingssystemen te draaien op dezelfde hardware. Al deze verschillende besturingssystemen worden dan virtuele machines (VM's) genoemd. “Virtualiteit” verschilt alleen van “werkelijkheid” in de formele wereld, terwijl zij eigenlijk een soortgelijke essentie of werking bezit. In de computerwereld wordt een virtuele omgeving waargenomen als die van een echte omgeving door zowel toepassingsprogramma's als de rest van de wereld, hoewel de onderliggende mechanismen formeel wel verschillend zijn \autocite{Radhwan2013}.

Virtuele machines zijn al meer dan 50 jaar in de computergemeenschap, ontwikkeld in 1960 door IBM Corporation, oorspronkelijk was dit om een grote mainframe computer te verdelen in verschillende instanties. Deze functie werd uitgevonden omdat het onderhoud van de grotere mainframe systemen omslachtig werd. Door het systeem te partitioneren, maakt het het mogelijk meerdere processen en toepassingen gelijktijdig te kunnen draaien, waardoor de efficiëntie en onderhoudskosten van de omgevingen verminderen. Onder toezicht en leiding van Professor Fernando J. Corbató beter bekend als 'Corby', zijn de ingenieurs en programmeurs begonnen met CTSS, de “Compatible Time-Sharing System” \autocite{Radhwan2013}.

De CTSS-supervisor leverde een aantal virtuele machines, allemaal een IBM 7094. Een van deze virtuele machines was de achtergrondmachine en had toegang tot tapedrives(Een tapedrive is ene opslag apparaat). De andere virtuele machines waren voorgrondmachines. Deze machines konden normale 7094-machinetaal draaien met een snelheid van 7094 en konden ook een extra instructie uitvoeren, die een groot aantal 'supervisorservices' opriep. Deze 'services' omvatten de terminal-I/O en systeem-I/O. Programma's kunnen worden geschreven voor de voorgrondmachine in elke taal die beschikbaar is voor de 7094. Er werden bibliotheken beschikbaar gesteld zodat compilertalen zoals MAD gebruik konden maken van die 'supervisorservices'. CTSS leverde een bestandssysteem dat elke geregistreerde gebruiker een aparte map met bestanden gaf \autocite{VanVleck2015}.

De belangrijkste kenmerken van CTSS waren virtuele machines, hardware isolatie van gebruikers van de supervisor en van elkaar, en een bestandssysteem per gebruiker. Omdat de virtuele gebruikersmachine dezelfde architectuur en instructieset ondersteunde als de 7094, kon CTSS een groot aantal applicaties ondersteunen die oorspronkelijk waren ontwikkeld voor de FMS-batchomgeving bij MIT en elders \autocite{VanVleck2015}.

CTSS-software omvatte niet alleen de supervisor, maar ook een reeks voorgrond-opdrachten en subroutine bibliotheken. Veel van deze  opdrachten lezen en schrijven bestanden van het bestandssysteem van de gebruiker. Zo las bijvoorbeeld de MAD-compiler een bestand met de broncode van een programma en schreef hetzelfde bestand met instructies in BSS(block starting symbol) formaat. Het grootste deel van de MAD-opdrachten op de voorgrond waren gelijk aan de MAD-compiler op de achtergrond op de FMS systeemtape, met de toevoeging van een wrapper voor het afhandelen van opdrachtprompt opties en vervangingen voor de invoer- en uitvoerroutines om bestanden te lezen en te schrijven in plaats van tape, en om foutmeldingen naar de terminal van de gebruiker te schrijven \autocite{VanVleck2015}.

In 1973 demonstreren Srodowa en Bates hoe je een virtuele machine kan maken op de IBM OS/360s. Ze beschrijven het gebruik van de IBM's virtuele machine monitor, de hypervisor om virtuele machines te maken en het efficiënt toewijzen van geheugen, opslag en I/O. Beiden hebben betrekking op onderwerpen die vandaag nog steeds worden bediscussieerd: prestatievermindering, capaciteit, CPU-toewijzing en opslag beveiliging. In 1974 concludeert Goldberg dat het merendeel van de toenmalige computersystemen geen virtuele machines ondersteunen. De weinige virtuele machines die op dat moment operationeel zijn, bijvoorbeeld CP-67, gebruiken lastige en inadequate technieken vanwege ongeschikte architecturen. Goldberg stelt de “Hardware Virtualizer” voor, waarin een virtuele machine rechtstreeks zou communiceren met hardware in plaats van door de hostsoftware te gaan. Bijna 30 jaar later zijn brancheanalisten enthousiast over de aankondiging van hardware-architecturen die virtuele machines efficiënt kunnen ondersteunen. Zowel AMD als Intel onthulden specificaties voor Pacifica en Vanderpool chiptechnologieën met speciale virtualisatie-ondersteuningsfuncties \autocite{Radhwan2013}.

De jaren tachtig en begin jaren negentig brachten het 'Distributed computing', wat een techniek is waarbij rekentaken niet door één enkele computer worden uitgevoerd,  met zich mee naar de datacenters. Gecentraliseerd computergebruik en virtuele machines werden vervangen door stand-alone servers met specifieke taken: databank, web, applicaties, e-mail. Na aanzienlijke investeringen in gedistribueerde architecturen, is een hernieuwde focus op virtuele machines als aanvullende oplossing voor serverconsolidatieprojecten en datacenter beheerinitiatieven weer opgedoken. De virtuele machine is dus gemaakt op de mainframe. Het is pas onlangs geïntroduceerd op de middenklasse. Technologische vooruitgang in hardware en software maakt virtuele machines stabiel, betaalbaar en biedt enorme waarde, mits een juiste implementatie \autocite{Jeff2009}.

Sinds begin 2000 is de opkomst van VMware hun VMware Workstation sterk gestegen. VMware werkt met een “Hosted Architecture”, dit wil zeggen dat de host een operating system nodig heeft zoals Windows of Linux. Om de complexe mix van prestaties, draagbaarheid, implementatiegemak, enz. te optimaliseren, fungeert het product zowel als een virtuele Machine Monitor(VMM) (rechtstreeks in gesprek met de hardware) als  een applicatie die bovenop het hostbesturingssysteem draait. Dit laatste zorgt er voor dat de VMM niet moet omgaan met een groot aantal apparaten beschikbaar op de computers \autocite{Singh2004}.

Het meest essentiële onderdeel van die virtualisatie is dus de Hypervisor, en wordt ook wel de Virtual Machine Monitor genoemd. De Hypervisor creëert een virtueel platform op de host om daarop meerdere gast besturingssystemen te draaien. Op deze manier kunnen meerdere dezelfde of verschillende exemplaren van een besturingssysteem draaien, en de hardwarebronnen delen die door de host worden aangeboden. Datacenters gebruiken tegenwoordig virtualisatie om abstractie te maken van de fysieke hardware, en deze bronnen aan gebruikers of klanten aan te bieden in de vorm van agile, schaalbare, geconsolideerde virtuele machines. Hoewel de technologie en de gebruiksredenen geëvolueerd zijn, blijft de kernbetekenis van virtualisatie hetzelfde: één host besturingssysteem in staat stellen om meerdere onafhankelijke besturingssystemen tegelijkertijd te laten draaien \autocite{Oracle2012}.

\subsection{Verschillende typen virtualisatie}

Virtualisatie maakt een scheiding van onderliggende hardware mogelijk, wat ervoor zorgt dat je op een hoger niveau bewerkingen kan uitvoeren. Virtualisatietechnologie kan worden onderverdeeld in de volgende: 

\subsubsection{Full virtualisatie}

In full virtualisatie is de hardware-interface die wordt aangeboden aan de hypervisor bijna dezelfde als die wordt geboden door het fysieke toestel. Dit betekent dat er voor virtualisatie weinig tot geen wijziging nodig is aan de besturingssystemen en applicaties als deze compatibel zijn met de hardware van het fysieke toestel. Deze virtualisatie kan worden onderverdeeld in zowel “Bare-metal virtualisatie” als “Hosted virtualisatie”. Bij bare-metal virtualisatie is er geen hostbesturingssysteem, dit wil zeggen dat de hypervisor rechtstreeks draait op de onderliggende hardware. Hosted virtualisatie wil zeggen dat het hostbesturingssysteem elk algemeen besturingssysteem kan zijn, zoals Windows, zoals Linux, etc. waarop de hypervisor draait. Deze virtualisatie heeft een extra softwarelaag die in het gast besturingssysteem draait en aan de hand van hulpprogramma's het mogelijk maakt om tijdens het gebruik van het gast besturingssysteem, toch bestanden te delen met de host \autocite{Kedia2013}.

\subsubsection{Para virtualisatie}

Paravirtualisatie of para-virtualisatie is een virtualisatietechniek die een software-interface presenteert aan de virtuele machines die vergelijkbaar is, maar niet identiek, aan de onderliggende hardware/software interface. Het voordeel van deze techniek is dat het de overheadkosten voor virtualisatie vermindert en betere prestaties levert \autocite{Kedia2013}.

\subsubsection{Operating system virtualisatie}

De kernel staat meerdere geïsoleerde besturingssystemen toe. Deze instanties draaien op een bestaand besturingssysteem en geven een reeks bibliotheken weer waarmee applicaties communiceren, waardoor ze de illusie krijgen dat ze worden uitgevoerd op een machine die speciaal voor het gebruik ervan bedoeld is. Deze virtualisatie staat beter bekend als container virtualisatie, wat later nog aan bod zal komen \autocite{Kedia2013}.

\subsubsection{Desktop virtualisatie}

Desktop virtualisatie is een mechanisme om een PC omgeving met centrale applicaties vanaf een centrale server weer te geven. Het stelt gebruikers in staat applicaties voor verschillende besturingssystemen op een enkele host uit te voeren. Het biedt flexibiliteit om de applicaties en clients te verplaatsen wanneer nodig \autocite{Kedia2013}.

\subsubsection{Server virtualisatie}

Bij server virtualisatie wordt basishardware gevirtualiseerd, waardoor gast besturingssystemen die er op draaien zonder de nood van de gehele operating system kunnen opereren. Servervirtualisatie is het proces waarbij een fysieke server wordt opgedeeld in meerdere unieke en geïsoleerde virtuele servers \autocite{Kedia2013}.

\subsubsection{Applicatie virtualisatie}

Bij deze virtualisatie kan een gebruiker een servertoepassing lokaal draaien met behulp van lokale bronnen zonder de applicatie volledig lokaal te installeren. Het biedt elke gebruiker een geïsoleerde virtuele applicatieomgeving die fungeert als een laag tussen de host en het besturingssysteem. Een voorbeeld van deze soort virtualisatie is een Java Virtual Machine(JVM), aangezien het staat tussen het besturingssysteem en de java-applicatiecode \autocite{Kedia2013}. 

\subsubsection{Storage virtualisatie}

Opslag virtualisatie is een techniek waarbij de opslag van gegevens uit een fysieke opslag wordt opgehaald en over het netwerk wordt verspreid. Dit is een vorm van resource-virtualisatie. Dit wordt vaak gebruikt in een Storage Area Network(SAN) \autocite{Kedia2013}.

\subsubsection{Network virtualisatie}

Netwerk virtualisatie is het proces waarbij hard- en softwarebronnen gecombineerd worden tot een virtueel netwerk als één enkele verzameling bronnen. Het zorgt voor een beter infrastructuur gebruik, zoals het hergebruik van poorten en fysieke bronnen, voor meerdere andere netwerkbronnen zoals hosts, virtuele machines, routers, switches etc. Zo helpt het ook bij verlagen van de kosten door netwerkbronnen te delen \autocite{Kedia2013}.

\subsubsection{Resource virtualisatie}

Resource virtualisatie wordt beschouwd als opslagvolumes, namespaces en de netwerkbronnen in een gevirtualiseerd systeem. Alle onderdelen kunnen samen een grotere pool van bronnen worden en zo kan één enkele bron, zoals schrijfruimte, ook worden opgedeeld in een aantal kleinere en gemakkelijk toegankelijke bronnen \autocite{Kedia2013}.

\subsection{Container virtualisatie}

\subsubsection{Wat is container virtualisatie}

Containergebaseerde virtualisatie is een lichtere benadering van virtualisatie met behulp van de host-kernel om meerdere virtuele omgevingen te draaien. Deze virtuele omgevingen worden meestal benoemd als containers. Containergebaseerde virtualisatie virtualiseert op het besturingssysteem niveau, en laat dus toe om meerdere applicaties te draaien zonder redundante host-kernels van andere machines. De containers zien eruit als normale processen van de buitenkant, die bovenop de kernel draaien die gedeeld wordt met de host. Ze bieden een geïsoleerde omgeving met de nodige middelen om applicaties uit te voeren. Deze middelen worden gedeeld met de host of afzonderlijk per container ter beschikking gesteld \autocite{Thanh2015}.

\subsubsection{Verschil tussen containers en virtuele machines}
Containergebaseerde virtualisatie zorgt voor sommige voordelen tegenover een hypervisor-gebaseerde virtualisatie. Ten eerst zorgt een containergebaseerde virtualisatie voor een grotere dichtheid van virtuele omgevingen. Dit komt omdat een container geen volledig besturingssysteem heeft, de grootte en nodige middelen zijn ook minder om een applicatie in een container te draaien. Met als resultaat dat meerdere containergebaseerde virtuele machines opgezet kunnen worden op dezelfde machines t.o.v. traditionele virtuele machines. Ten tweede zorgen containers voor een betere performance \autocite{Ruiz2015}.

Deze studies tonen aan dat de performance van containergebaseerde virtualisatie beter is dan met een hypervisor-gebaseerde virtualisatie in de meeste gevallen. Echter, desondanks het genoemde voordeel is containergebaseerde virtualisatie niet in staat om een verschil in virtuele omgevingen te ondersteunen, zoals een hypervisor dat wel kan. De oorzaak hiervan is, dat containers hetzelfde type moeten zijn als de host. Zo kan bijvoorbeeld een Windows host niet draaien op een Linux host. Aan de hand van een hypervisor-gebaseerde virtuele machine kan dat wel, waardoor je zowel Windows als Linux containers op een Linux host kan draaien \autocite{Ruiz2015}.

\subsubsection{Kubernetes}
Kubernetes is een draagbaar, uitbreidbaar, opensource platform voor het beheren van gecontaineriseerde workloads en services, dat zowel manuele configuratie als automatisering mogelijk maakt \autocite{Kubernetes2021}.

De kracht van Kubernetes is het uitvoeren van workloads op meerdere servers. Het is één van de beste tools als het gaat om containerclusterbeheer. Het voert de juiste containers op het juiste moment uit, schaalt ze op en neer op basis van belasting, lost hardware- of containerstoringen op en beheert netwerken en opslag \autocite{Rancher2020}.

Origineel ontwikkeld door Google, geïnspireerd door een decennia van kennis door het uitrollen van schaalbare en betrouwbare systemen in containers door applicatie georiënteerde APIs. Sinds de introductie in 2014 is Kubernetes één van de grootste en meest populaire open source projecten in de wereld. Het is de standaard API geworden voor het bouwen van cloud-native applicaties, present in bijna elke publieke cloud. Kubernetes is een bewezen infrastructuur voor gedistribueerde systemen dat geschikt is voor cloud-native ontwikkelaars van alle schalen, zo kan het gaan over een cluster van een aantal Raspberry Pi's tot een warenhuis met de nieuwste computers. Het zorgt voor de nodige software om succesvol betrouwbare en schaalbare systemen op te zetten \autocite{Burns2019}.


\subsubsection{Alternatief voor Kubernetes}
Hoewel er veel voordelen zijn voor het gebruik van Kubernetes, denk maar aan documentatie en support van de community, is het niet mis om de alternatieven te bekijken. Amazon Elastic Container Service, Mirantis Kubernetes Engine (Docker Enterprise) zijn hier goede voorbeelden van. Daar dit onderzoek gaat over monitoring zal hier verder geen vergelijking plaatsvinden.

\subsubsection{Docker}
Docker is een source-platform waarop applicaties worden uitgevoerd en het proces gemakkelijker te ontwikkelen en distribueren is. De applicaties die in Docker gebouwd zijn, worden met alle ondersteunende afhankelijkheden verpakt in een zogenaamde container. De containers blijven op een geïsoleerde manier draaien bovenop de kernel van het besturingssysteem. De extra abstractielaag kan invloed hebben op de prestaties. Hoewel containervirtualisatie al meer dan 10 jaar bestaat, is Docker, een relatief nieuwe technologie, zonder twijfel één van de beste omdat het capaciteiten heeft dat voorgaande technologieën niet hadden \autocite{Rad2017}.

In eerste instantie biedt Docker de mogelijkheid om containers te maken en te controleren. Deze applicaties kunnen dan makkelijk in een containers gestoken worden. Daarnaast kunnen deze gevirtualiseerde applicaties makkelijk overal worden gebruikt zonder enige wijziging. Tenslotte kan Docker gemakkelijk samenwerken met externe programma's die helpen bij het opstellen en beheren van Docker containers \autocite{Rad2017}.

\subsubsection{Alternatief voor Docker}
Hoewel Docker één van de populairste containertechnologieën is, zijn er andere technologieën die Docker voorafgegaan zijn, die ontstaan zijn op hetzelfde moment of meer recentelijk zijn geïntroduceerd. Het basisconcept van de programma's zijn in grote lijnen gelijk en dan komt het vaak aan op technische verschillen. Voorbeelden van andere goede containertechnologieën zijn RKT(Rocket, CoreOS), LXD(Lexdi, Canoncical Ltd.), Linux VServer en Windows Containers. Maar zoals vermeld in het “Alternatief voor Kubernetes” gaat dit onderzoek niet verder gaan de vergelijken van deze applicaties. 

\subsubsection{Samenwerking tussen Docker en Kubernetes}
In een Docker-cluster omgeving moeten enkele taken worden uitgevoerd, zoals plannen van deployments, communicatie en schaalbaarheid. Deze taken worden daarom uitgevoerd door orkestratietools, met als groot voorbeeld, Kubernetes. Kubernetes is één van de meest populaire projecten in de open source-geschiedenis \autocite{Journal2020}.

Docker helpt bij het maken van containers, en Kubernetes laat toe dat de gebruiker ze tijdens runtime kan beheren. Docker wordt gebruikt voor het verpakken en verzenden van de applicatie en Kubernetes om de applicatie te implementeren en te schalen. Wanneer er gebruik gemaakt wordt van een klein aantal containers is het gebruik van Kubernetes nog niet nodig, maar vanaf het aantal containers begint op te schalen is het wel aan te raden. Dit is ook waar Kubernetes in uitblinkt \autocite{Journal2020}. 

Wanneer ze samen worden gebruikt, dienen Docker en Kubernetes voor het inschakelen van digitale transformatie en als tool voor moderne cloudarchitectuur. Het gebruik van beide is een nieuwe norm in de branche en zorgt voor een snellere implementatie en release van applicaties \autocite{Journal2020}. 

\section{Monitoring}
\subsection{Wat is monitoring}
Monitoring is het proces om metrische gegevens te verzamelen over de werking van de hardware en software van een IT-infrastructuur om ervoor te zorgen dat alles functioneert zoals verwacht om applicaties en services te ondersteunen. Basis monitoring wordt uitgevoerd door middel van controle uit te voeren over de werking van een apparaat, terwijl meer geavanceerde monitoring gedetailleerde overzichten geeft van de operationele statussen, inclusief gemiddelde reactie tijden, aantal applicatie-instanties, foutboodschappen, CPU-gebruik en applicatie beschikbaarheid \autocite{TechTarget2020}.

IT monitoring verspreidt zich over 3 secties:\\
\textbf{Basis}. De infrastructuur is de onderste laag van een softwarestack en omvat zowel fysieke als virtuele apparaten, zoals servers, CPU's en VM's. \\
\textbf{Software}. Dit deel wordt ook wel de bewakingssectie genoemd en het analyseert wat er op de apparaten in de basis gebeurd, inclusief CPU-gebruik, geheugen gebruik, load op de servers enzovoort.\\
\textbf{Interpretatie}. Verzameld statistieken die worden gepresenteerd via grafieken of diagrammen, vaak op een GUI-dashboard. Dit wordt vaak bereikt door integratie met tools die specifiek gericht zijn op datavisualisatie.

Monitoring kan met of zonder 'agents'. Een agent is een onafhankelijk programma die op een apparaat wordt geïnstalleerd om gegevens over hardware of software, prestatiegegevens verzameld en rapporteert aan een monitoringserver. Wanneer er geen agent is, zal de monitoringserver gebruik maken van communicatieprotocollen om een agent te emuleren met ongeveer dezelfde functionaliteiten om zo gegevens te verzamelen \autocite{TechTarget2020}.

Er zijn ook twee soorten monitoring wanneer het over de frequentie gaat. Enerzijds is er 'Real Time Monitoring' wat een techniek is waarbij systemen continu gegevens verzamelen en toegankelijk zijn door IT-teams om de actieve en lopende status te bepalen. Metingen van real-time monitoringssoftware geven gegevens weer uit de huidige IT-omgeving, evenals het recente verleden, waardoor IT-personeel snel kunnen reageren op actuele gebeurtenissen. Door data op deze manier te monitoren, kan het IT-personeel de infrastructuur verbeteren of mogelijke complicaties identificeren voordat ze zich voordoen, omdat ze een patroon of trend in de gegevens herkennen. Anderzijds is er ook trend monitoring, een analyse van één specifieke gebeurtenis op een bepaald moment. Dit kan gebruikt worden om een probleem te identificeren dat onmiddellijk moet worden verholpen, zoals een 100\% volle schijf of overmatig gebruik van de cpu \autocite{TechTarget2020}.

\subsection{Wat is monitoring binnen een container environment}

De verandering van monitoring binnen een container omgeving kan uitgelegd worden in 5 verschillende punten:

\begin{itemize}
    \item De korte duur van containers
    \item De snelle groei van objecten, services en statistieken om te loggen
    \item Services zijn het nieuwe focuspunt van monitoring
    \item Een meer diverse groep van monitoring-eindgebruikers
    \item Nieuwe gedachten resulteren in nieuwe methoden
\end{itemize}

\subsubsection{Korte duur en schaal van containers}

De tijdelijke aard van containers en instanties van virtuele machines zorgt voor uitdagingen op het gebied van tracking. Omdat er op veel bewegende delen moet worden gericht vereist dit nieuwe monitoringmethoden om observaties te doen over de status van een container. Door de korte duur van containers en de snelgroeiende schaal heeft het weinig zin om container per container te bekijken, in plaats daarvan wordt aangeraden om clusters (meerdere containers) te volgen/monitoren. Traditionele benaderingen van monitoring zijn gebaseerd op het introduceren van datacollectors, genaamd 'agents' of 'remote access hooks' in de systemen zelf. Deze kunnen de snelheid van de provisioning en het dynamisch opschalen niet aan. Je kan op twee manieren data opvangen van een server, enerzijds door te 'pollen' en anderzijds door te 'pushen'. De tweede aanpak heeft een voorkeur voor een container omgeving, daar deze containers van korte duur zijn omdat het te lang kan duren om deze containers te vinden en te pollen. Om te kunnen pushen wordt een agent geïnstalleerd, wat het 'pol'-proces elimineert \autocite{Williams2016}. 

\subsubsection{Snelle groei van objecten, services en statistieken}

De explosie van gegenereerde gegevens is een bekend fenomeen. Vroeger vroegen mensen zich af hoe ze al die gegevens moeten opslaan, tegenwoordig ligt de nadruk meer op hoe die gegevens gebruikt kunnen worden zonder ze op te slaan. Door de opkomst van Internet of Things(IoT)-sensoren en de introductie van containers, zijn er nu meer objecten dan ooit om te monitoren. De overvloed aan datapunten, metrieken en objecten die moeten worden gevolgd, is een ernstig probleem. Het streamen van gegevens biedt veel mogelijkheden voor realtime analyses, maar het moet wel nog worden verwerkt en opgeslagen. Er zijn technische oplossingen die de schaal aankunnen, maar tegen aanzienlijke kosten voor zowel financiën als prestaties. Hoewel er wel databases van de volgende generatie zijn(NoSql), zijn ze niet geoptimaliseerd voor deze use case. Loggegevens kunnen echter niet voor onbepaalde tijd bewaard worden. Sommige oudere bestanden worden nooit gebruikt, wat gebruikers motiveert om eerder te focussen op metrische gegevens in plaats van logs. Metrische gegevens zijn gegevens die in geaggregeerde vorm of op regelmatige tijdstippen worden verzameld \autocite{Williams2016}.

\subsubsection{Services zijn het nieuwe aandachtspunt}

Met een hernieuwde focus op wat er daadwerkelijk gemonitord moet worden, zijn er drie aandachtsgebieden: de gezondheid van containerclusters, microservices en toepassingen. Het beoordelen van clusters van containers - in plaats van afzonderlijke containers - is een betere manier voor infrastructuurbeheerders om de impact van services te begrijpen. Hoewel het waar is dat applicatiebeheerders individuele containers kunnen uitschakelen en herstarten, zijn ze meer geïnteresseerd in het begrijpen welke clusters gezond zijn. Met deze informatie kunnen ze het cluster inzetten op een andere infrastructuur of extra bronnen toevoegen om de optimale werking ervan te ondersteunen. Containerorkestratie-oplossingen helpen door een efficiënte planning van containers op clusters van hosts mogelijk te maken. Volgens Dynatrace Cloud Technology Lead Alois Mayr, in een interview met The New Stack: ''als je kijkt naar applicatiebewaking, ben je vooral geïnteresseerd in de services die in containers worden uitgevoerd, in plaats van in de containers zelf'' \autocite{Williams2016}.

\subsubsection{Een meer diverse groep van monitoring-eindgebruikers}

De focus op het monitoren van applicaties in plaats van alleen op infrastructuur gebeurt om twee redenen. Allereerst is er een nieuwe groep mensen bij de monitoring betrokken. Ten tweede zijn applicaties relevanter voor de algehele bedrijfsprestaties. 

Ondanks de vooruitgang van de afgelopen jaren is de monitoring over het algemeen nog steeds reactief. Het is gericht op de doelstellingen van het IT-team dat de feitelijke infrastructuur beheert. Deze mentaliteit bewijst ontwikkelaars een slechte dienst, omdat ze over het algemeen gegevens uit de tweede hand ontvangen. Ontwikkelaars worden steeds vaker aangesproken op applicaties nadat ze in productie zijn genomen. Zoals de ''Effective Performance Engineering'' van Todd DeCapua en Shane Evans opmerkt, wordt ontwikkelaars gevraagd om ''producten van de hoogste kwaliteit te leveren en continue feedback en optimalisatieaanbevelingen te geven, zodat andere teams snel en volledig geautomatiseerd kunnen opleveren.'' De DevOps-beweging is gestegen, althans gedeeltelijk, als reactie op het verlangen van ontwikkelaars naar meer zichtbaarheid gedurende de volledige levenscyclus van een applicatie. Nu zijn DevOps-rollen vaak de volledige stackbeheerders en operators van applicaties. 

Samen met DevOps zal de praktijk van ''site reliability engineering (SRE)'' van invloed zijn op het gebruik van monitoringtools. Vanuit dit perspectief zal de monitoring nog steeds grotendeels worden beheerd door een operationeel team, maar de verantwoordelijkheid om ervoor te zorgen dat nieuwe applicaties en services worden gecontroleerd, kan worden gedelegeerd aan applicatieontwikkelaars. Shariq Rizvi, mede-oprichter van Netsil, zei in een interview met The New Stack dat SRE's en DevOps-ingenieurs anders zijn dan software-ingenieurs. Hij vindt dat SRE-teams het beheer van diensten moeten opsplitsen, waardoor er meer specialisatie ontstaat. Dan Turchin, mede-oprichter en ''chief product officer'' van Neva, zei in een interview met The New Stack dat hij gelooft dat DevOps-functies de technici van het ''Network Operations Center (NOC)'' vervangen, die traditioneel vanuit het perspectief van een datacenter naar de dingen keken. Als de ouderwetse netwerkstatistieken worden verdrongen door statistieken van de cloudinfrastructuur, kan dit waar zijn \autocite{Williams2016}. 

\subsubsection{Nieuwe gedachten resulteren in nieuwe methoden}

Hoewel monitoring verandert om aan de behoeften van verschillende functies te voldoen, gaat het ook over een meer alomvattende benadering. Majors Charity, blogger bij ''Honeycomb.io''\autocite{Majors2016}, vertelt dat in plaats van te vertrouwen op een vaste reeks vragen en controles, mensen zouden moeten evolueren naar de “observeerbaarheid” van systemen. Dit moet gebeuren omdat die vaste datapunten alleen, niet de benodigde inzichten opleveren. Er zijn nieuwe tools nodig om gelijke tred te houden en de mogelijkheid te bieden om te voorspellen wat er gaat breken. Veel van deze tools maken gebruik van artificiële intelligentietechnieken. 

Observeerbaarheid erkent dat testen het probleem niet altijd identificeert. Majors is dan ook van mening dat “instrumentatie net zo belangrijk is als testen. Als je complexe systemen gebruikt, kun je niet alles in je hoofd modelleren.” Naast het veranderen van de instrumentatie, stelt ze ook voor om te focussen op het begrijpbaar maken van de monitoringssystemen. Dit betekent feitelijk definiëren wat de gegevens vertegenwoordigen en dezelfde definities gebruiken als uw collega's, zowel binnen als buiten de organisatie. Verder is er ook frustratie over de noodzaak om door meerdere, statische dashboards te scrollen. Als reactie hierop maken ontwikkelaars meer intuïtieve, interactieve dashboards en maken zelf gebruik van artificiële intelligentie om voor elke server te bepalen welke informatie wanneer wordt weergegeven \autocite{Williams2016}.

\subsection{Wat is het nut/belang van monitoring in het lessenpakket}

\subsection{Wat zijn de prerequisites/voorwaarden van de tool}

\subsection{Welke tools zijn er om te monitoren}

%TODO onderzoeken welke tools veel gebruikt worden(marktonderzoek), top 10 ofzo